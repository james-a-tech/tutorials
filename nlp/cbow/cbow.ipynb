{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CBOW model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>movie</td>\n",
       "      <td>was</td>\n",
       "      <td>boring</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>movie</td>\n",
       "      <td>actions</td>\n",
       "      <td>were</td>\n",
       "      <td>very</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>movie</td>\n",
       "      <td>was</td>\n",
       "      <td>good</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>movie</td>\n",
       "      <td>story</td>\n",
       "      <td>was</td>\n",
       "      <td>very</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0        1       2     3     4\n",
       "0  movie      was  boring  None  None\n",
       "1  movie  actions    were  very  good\n",
       "2  movie      was    good  None  None\n",
       "3  movie    story     was  very   bad"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "corpus = [\n",
    "    \"Movie was boring\",\n",
    "    \"Movie actions were very good\",\n",
    "    \"Movie was good\",\n",
    "    \"Movie story was very bad\"\n",
    "]\n",
    "\n",
    "# Preprocessing: \n",
    "##  tokenize the sentences\n",
    "def tokenize_corpus(corpus):\n",
    "    tokens = [sentence.lower().split() for sentence in corpus]\n",
    "    return tokens\n",
    "\n",
    "tokenized_corpus = tokenize_corpus(corpus)\n",
    "\n",
    "pd.DataFrame(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unique set of words in the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'actions', 'bad', 'boring', 'good', 'movie', 'story', 'very', 'was', 'were'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build vocabulary and mappings\n",
    "vocab = set()\n",
    "for sentence in tokenized_corpus:\n",
    "    vocab.update(sentence)\n",
    "\n",
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign a unique index to each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>was</th>\n",
       "      <th>good</th>\n",
       "      <th>movie</th>\n",
       "      <th>actions</th>\n",
       "      <th>bad</th>\n",
       "      <th>very</th>\n",
       "      <th>story</th>\n",
       "      <th>boring</th>\n",
       "      <th>were</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   was  good  movie  actions  bad  very  story  boring  were\n",
       "0    0     1      2        3    4     5      6       7     8"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_index = {word: i for i, word in enumerate(vocab)}\n",
    "index_to_word = {i: word for word, i in word_to_index.items()}\n",
    "vocab_size = len(word_to_index)\n",
    "word_to_index, index_to_word\n",
    "\n",
    "pd.DataFrame([word_to_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Define context and target words for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['was'], 'movie'),\n",
       " (['movie', 'boring'], 'was'),\n",
       " (['was'], 'boring'),\n",
       " (['actions'], 'movie'),\n",
       " (['movie', 'were'], 'actions'),\n",
       " (['actions', 'very'], 'were'),\n",
       " (['were', 'good'], 'very'),\n",
       " (['very'], 'good'),\n",
       " (['was'], 'movie'),\n",
       " (['movie', 'good'], 'was'),\n",
       " (['was'], 'good'),\n",
       " (['story'], 'movie'),\n",
       " (['movie', 'was'], 'story'),\n",
       " (['story', 'very'], 'was'),\n",
       " (['was', 'bad'], 'very'),\n",
       " (['very'], 'bad')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_training_data(tokenized_corpus, window_size=1):\n",
    "    training_data = []\n",
    "    for sentence in tokenized_corpus:\n",
    "        for i, word in enumerate(sentence):\n",
    "            context = []\n",
    "            for j in range(-window_size, window_size + 1):\n",
    "                if j != 0 and 0 <= i + j < len(sentence):\n",
    "                    context.append(sentence[i + j])\n",
    "            target = word\n",
    "            training_data.append((context, target))\n",
    "    return training_data\n",
    "\n",
    "training_data = generate_training_data(tokenized_corpus)\n",
    "\n",
    "training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating training matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.707264</td>\n",
       "      <td>0.871984</td>\n",
       "      <td>-0.866987</td>\n",
       "      <td>-0.621605</td>\n",
       "      <td>0.685625</td>\n",
       "      <td>0.671544</td>\n",
       "      <td>0.949171</td>\n",
       "      <td>-0.701265</td>\n",
       "      <td>0.163057</td>\n",
       "      <td>-0.856476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.175688</td>\n",
       "      <td>-0.912535</td>\n",
       "      <td>0.945804</td>\n",
       "      <td>-0.628869</td>\n",
       "      <td>0.434738</td>\n",
       "      <td>-0.392405</td>\n",
       "      <td>0.591259</td>\n",
       "      <td>-0.131291</td>\n",
       "      <td>-0.598987</td>\n",
       "      <td>0.923839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.950587</td>\n",
       "      <td>-0.877492</td>\n",
       "      <td>-0.004931</td>\n",
       "      <td>-0.498021</td>\n",
       "      <td>-0.513240</td>\n",
       "      <td>0.656964</td>\n",
       "      <td>-0.496648</td>\n",
       "      <td>0.607605</td>\n",
       "      <td>-0.355421</td>\n",
       "      <td>0.385362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.470238</td>\n",
       "      <td>0.821604</td>\n",
       "      <td>0.184242</td>\n",
       "      <td>-0.993730</td>\n",
       "      <td>0.590488</td>\n",
       "      <td>0.328958</td>\n",
       "      <td>0.760862</td>\n",
       "      <td>-0.281472</td>\n",
       "      <td>0.113409</td>\n",
       "      <td>0.278888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.203614</td>\n",
       "      <td>-0.303613</td>\n",
       "      <td>-0.571385</td>\n",
       "      <td>-0.420684</td>\n",
       "      <td>-0.018658</td>\n",
       "      <td>0.416891</td>\n",
       "      <td>0.176079</td>\n",
       "      <td>0.936392</td>\n",
       "      <td>-0.979797</td>\n",
       "      <td>0.488660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.726533</td>\n",
       "      <td>0.775927</td>\n",
       "      <td>-0.178288</td>\n",
       "      <td>-0.383613</td>\n",
       "      <td>0.983372</td>\n",
       "      <td>-0.769543</td>\n",
       "      <td>0.597816</td>\n",
       "      <td>-0.966627</td>\n",
       "      <td>0.135263</td>\n",
       "      <td>0.852387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.354482</td>\n",
       "      <td>-0.252654</td>\n",
       "      <td>0.376925</td>\n",
       "      <td>0.279722</td>\n",
       "      <td>-0.339790</td>\n",
       "      <td>-0.245940</td>\n",
       "      <td>-0.863511</td>\n",
       "      <td>-0.662389</td>\n",
       "      <td>0.741874</td>\n",
       "      <td>-0.237106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.919164</td>\n",
       "      <td>0.239099</td>\n",
       "      <td>0.706737</td>\n",
       "      <td>0.787357</td>\n",
       "      <td>0.285884</td>\n",
       "      <td>0.443212</td>\n",
       "      <td>-0.468733</td>\n",
       "      <td>0.033076</td>\n",
       "      <td>-0.229903</td>\n",
       "      <td>-0.402908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.573819</td>\n",
       "      <td>-0.735416</td>\n",
       "      <td>-0.980552</td>\n",
       "      <td>-0.317224</td>\n",
       "      <td>0.562350</td>\n",
       "      <td>-0.193679</td>\n",
       "      <td>0.827143</td>\n",
       "      <td>-0.457183</td>\n",
       "      <td>-0.373474</td>\n",
       "      <td>-0.527231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.707264  0.871984 -0.866987 -0.621605  0.685625  0.671544  0.949171   \n",
       "1 -0.175688 -0.912535  0.945804 -0.628869  0.434738 -0.392405  0.591259   \n",
       "2 -0.950587 -0.877492 -0.004931 -0.498021 -0.513240  0.656964 -0.496648   \n",
       "3 -0.470238  0.821604  0.184242 -0.993730  0.590488  0.328958  0.760862   \n",
       "4  0.203614 -0.303613 -0.571385 -0.420684 -0.018658  0.416891  0.176079   \n",
       "5 -0.726533  0.775927 -0.178288 -0.383613  0.983372 -0.769543  0.597816   \n",
       "6  0.354482 -0.252654  0.376925  0.279722 -0.339790 -0.245940 -0.863511   \n",
       "7  0.919164  0.239099  0.706737  0.787357  0.285884  0.443212 -0.468733   \n",
       "8 -0.573819 -0.735416 -0.980552 -0.317224  0.562350 -0.193679  0.827143   \n",
       "\n",
       "          7         8         9  \n",
       "0 -0.701265  0.163057 -0.856476  \n",
       "1 -0.131291 -0.598987  0.923839  \n",
       "2  0.607605 -0.355421  0.385362  \n",
       "3 -0.281472  0.113409  0.278888  \n",
       "4  0.936392 -0.979797  0.488660  \n",
       "5 -0.966627  0.135263  0.852387  \n",
       "6 -0.662389  0.741874 -0.237106  \n",
       "7  0.033076 -0.229903 -0.402908  \n",
       "8 -0.457183 -0.373474 -0.527231  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "embedding_dim = 10\n",
    "learning_rate = 0.001\n",
    "epochs = 10000\n",
    "\n",
    "# Weight initialization\n",
    "W1 = np.random.uniform(-1, 1, (vocab_size, embedding_dim))  # Input to hidden weights\n",
    "W2 = np.random.uniform(-1, 1, (embedding_dim, vocab_size))  # Hidden to output weights\n",
    "\n",
    "pd.DataFrame(W1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and generating word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000, Loss: 9.5670\n",
      "Epoch 2000, Loss: 7.0455\n",
      "Epoch 3000, Loss: 6.3769\n",
      "Epoch 4000, Loss: 6.1014\n",
      "Epoch 5000, Loss: 5.9584\n",
      "Epoch 6000, Loss: 5.8731\n",
      "Epoch 7000, Loss: 5.8174\n",
      "Epoch 8000, Loss: 5.7785\n",
      "Epoch 9000, Loss: 5.7501\n",
      "Epoch 10000, Loss: 5.7285\n"
     ]
    }
   ],
   "source": [
    "# One-hot encoding function\n",
    "def one_hot_vector(word, word_to_index):\n",
    "    one_hot = np.zeros(vocab_size)\n",
    "    one_hot[word_to_index[word]] = 1\n",
    "    return one_hot\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    loss = 0\n",
    "    for context, target in training_data:\n",
    "        # Forward pass\n",
    "        context_vectors = np.sum([one_hot_vector(word, word_to_index) for word in context], axis=0)\n",
    "        h = np.dot(context_vectors, W1)  # Hidden layer\n",
    "        u = np.dot(h, W2)  # Output layer\n",
    "        y_pred = np.exp(u) / np.sum(np.exp(u)) # Softmax activation\n",
    "        \n",
    "        # Calculate loss (cross-entropy)\n",
    "        target_one_hot = one_hot_vector(target, word_to_index)\n",
    "        loss += -np.sum(target_one_hot * np.log(y_pred + 1e-8))\n",
    "\n",
    "        # Backpropagation\n",
    "        e = y_pred - target_one_hot\n",
    "        dW2 = np.outer(h, e)\n",
    "        dW1 = np.outer(context_vectors, np.dot(W2, e))\n",
    "\n",
    "        # Update weights\n",
    "        W1 -= learning_rate * dW1\n",
    "        W2 -= learning_rate * dW2\n",
    "\n",
    "    # Print loss every 1000 epochs\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(f'Epoch {epoch + 1}, Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>was</th>\n",
       "      <th>good</th>\n",
       "      <th>movie</th>\n",
       "      <th>actions</th>\n",
       "      <th>bad</th>\n",
       "      <th>very</th>\n",
       "      <th>story</th>\n",
       "      <th>boring</th>\n",
       "      <th>were</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.226012</td>\n",
       "      <td>-0.685008</td>\n",
       "      <td>-1.773884</td>\n",
       "      <td>-0.415146</td>\n",
       "      <td>0.301805</td>\n",
       "      <td>-0.378394</td>\n",
       "      <td>-1.652500</td>\n",
       "      <td>-1.027951</td>\n",
       "      <td>0.354144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.988148</td>\n",
       "      <td>-0.441821</td>\n",
       "      <td>0.659642</td>\n",
       "      <td>-1.628279</td>\n",
       "      <td>-0.665754</td>\n",
       "      <td>1.481087</td>\n",
       "      <td>-0.004331</td>\n",
       "      <td>0.675660</td>\n",
       "      <td>-1.434280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.117835</td>\n",
       "      <td>0.515531</td>\n",
       "      <td>-0.136495</td>\n",
       "      <td>0.252435</td>\n",
       "      <td>-0.821430</td>\n",
       "      <td>-0.925796</td>\n",
       "      <td>0.633450</td>\n",
       "      <td>0.505873</td>\n",
       "      <td>-0.891902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.969744</td>\n",
       "      <td>0.585738</td>\n",
       "      <td>0.767863</td>\n",
       "      <td>0.717832</td>\n",
       "      <td>-1.287798</td>\n",
       "      <td>-0.862781</td>\n",
       "      <td>-0.220741</td>\n",
       "      <td>0.720866</td>\n",
       "      <td>-0.094789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.372613</td>\n",
       "      <td>0.256785</td>\n",
       "      <td>1.127048</td>\n",
       "      <td>-0.139056</td>\n",
       "      <td>0.986007</td>\n",
       "      <td>-0.086398</td>\n",
       "      <td>0.734862</td>\n",
       "      <td>-0.355017</td>\n",
       "      <td>-0.495644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.791518</td>\n",
       "      <td>0.146677</td>\n",
       "      <td>0.767615</td>\n",
       "      <td>1.383622</td>\n",
       "      <td>0.556307</td>\n",
       "      <td>-2.177009</td>\n",
       "      <td>1.599112</td>\n",
       "      <td>-0.932217</td>\n",
       "      <td>0.240020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.064870</td>\n",
       "      <td>1.476541</td>\n",
       "      <td>-1.915478</td>\n",
       "      <td>0.530619</td>\n",
       "      <td>-0.003385</td>\n",
       "      <td>0.628305</td>\n",
       "      <td>0.805629</td>\n",
       "      <td>0.916441</td>\n",
       "      <td>-0.110245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.716644</td>\n",
       "      <td>-1.571887</td>\n",
       "      <td>-0.699909</td>\n",
       "      <td>1.392141</td>\n",
       "      <td>-2.098957</td>\n",
       "      <td>-0.418843</td>\n",
       "      <td>0.329034</td>\n",
       "      <td>-0.657582</td>\n",
       "      <td>-1.036781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.309886</td>\n",
       "      <td>-0.355030</td>\n",
       "      <td>0.859751</td>\n",
       "      <td>-1.784142</td>\n",
       "      <td>-0.423709</td>\n",
       "      <td>0.120963</td>\n",
       "      <td>-1.608760</td>\n",
       "      <td>-0.427513</td>\n",
       "      <td>-0.556890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-1.011330</td>\n",
       "      <td>-0.704604</td>\n",
       "      <td>1.082053</td>\n",
       "      <td>1.043992</td>\n",
       "      <td>0.085216</td>\n",
       "      <td>1.130337</td>\n",
       "      <td>-0.908654</td>\n",
       "      <td>-0.124562</td>\n",
       "      <td>0.375912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        was      good     movie   actions       bad      very     story  \\\n",
       "0  1.226012 -0.685008 -1.773884 -0.415146  0.301805 -0.378394 -1.652500   \n",
       "1  0.988148 -0.441821  0.659642 -1.628279 -0.665754  1.481087 -0.004331   \n",
       "2 -0.117835  0.515531 -0.136495  0.252435 -0.821430 -0.925796  0.633450   \n",
       "3  0.969744  0.585738  0.767863  0.717832 -1.287798 -0.862781 -0.220741   \n",
       "4 -1.372613  0.256785  1.127048 -0.139056  0.986007 -0.086398  0.734862   \n",
       "5  0.791518  0.146677  0.767615  1.383622  0.556307 -2.177009  1.599112   \n",
       "6  1.064870  1.476541 -1.915478  0.530619 -0.003385  0.628305  0.805629   \n",
       "7  0.716644 -1.571887 -0.699909  1.392141 -2.098957 -0.418843  0.329034   \n",
       "8 -0.309886 -0.355030  0.859751 -1.784142 -0.423709  0.120963 -1.608760   \n",
       "9 -1.011330 -0.704604  1.082053  1.043992  0.085216  1.130337 -0.908654   \n",
       "\n",
       "     boring      were  \n",
       "0 -1.027951  0.354144  \n",
       "1  0.675660 -1.434280  \n",
       "2  0.505873 -0.891902  \n",
       "3  0.720866 -0.094789  \n",
       "4 -0.355017 -0.495644  \n",
       "5 -0.932217  0.240020  \n",
       "6  0.916441 -0.110245  \n",
       "7 -0.657582 -1.036781  \n",
       "8 -0.427513 -0.556890  \n",
       "9 -0.124562  0.375912  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_dict = {}\n",
    "for word, idx in word_to_index.items():\n",
    "    embed_dict[word] = W1[idx]\n",
    "    # print(f'Word: {word}, Embedding: {W1[idx]}')\n",
    "\n",
    "import pandas as pd\n",
    "pd.DataFrame(embed_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the Euclidian distances b/w the word embeding to see the similarity b/w them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('boring', -0.0),\n",
       " ('good', -2.1010490666222092),\n",
       " ('very', -3.043933532973709),\n",
       " ('were', -3.4409453522364952),\n",
       " ('was', -3.513749970353083),\n",
       " ('story', -3.5137792092515623),\n",
       " ('bad', -4.042996161186965),\n",
       " ('movie', -4.146321741354841),\n",
       " ('actions', -4.325949285795467)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "def similar(target='beautiful'):\n",
    "    target_index = word_to_index[target] \n",
    "    scores = Counter() \n",
    "    for word,index in word_to_index.items(): \n",
    "        raw_difference = W1[index] - (W1[target_index]) \n",
    "        squared_difference = raw_difference * raw_difference \n",
    "        scores[word] = -math.sqrt(sum(squared_difference)) \n",
    "\n",
    "    return scores.most_common(10)\n",
    "\n",
    "similar('boring')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
