{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentimental classfication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('IMDB_Dataset.csv')\n",
    "df \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the vocabulary from the unique values from the text input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 439838\n"
     ]
    }
   ],
   "source": [
    "sent_tokens = df.review.map(lambda x: set(x.split(' ')))\n",
    "vocab = sent_tokens.explode().unique()\n",
    "print(f'Vocabulary size: {vocab.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assiging index values to each unique words in the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = {}\n",
    "for index , row in enumerate(sent_tokens):\n",
    "    for word in row:\n",
    "        word_index[word] = index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assigning index values for each words in the sentences , therby converting text into vector representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indieces len : 208\n",
      "Sentences : [49961, 0, 49997, 49999, 49709, 49986, 46765, 49997, 40906, 49998, 47564, 49997, 49801, 49995, 49999, 49532, 49951, 49995, 49964, 49108, 47739, 0, 49998, 49667, 49998, 49995, 49129, 49996, 49803, 49985, 49857, 49516, 41721, 3365, 41538, 49994, 49998, 49685, 49995, 49851, 49993, 33245, 49965, 49981, 49997, 49730, 49998, 49981, 49927, 49286, 49982, 49964, 49987, 49999, 49998, 49922, 49803, 49999, 47560, 42133, 49959, 49999, 49566, 49999, 49565, 46921, 49964, 49994, 0, 49999, 49122, 48890, 33546, 49992, 49559, 45752, 49588, 49993, 49743, 49999, 49998, 49996, 49953, 49998, 41568, 49853, 49758, 49976, 49988, 49229, 49998, 49998, 49999, 49997, 49999, 49982, 49992, 49966, 49997, 49991, 49994, 32801, 47645, 49991, 49915, 46561, 49952, 0, 49984, 49990, 48317, 46770, 49989, 49995, 49965, 49998, 49999, 49855, 49975, 49998, 49999, 49999, 49989, 48866, 3823, 49999, 49970, 49959, 49925, 0, 49997, 49729, 49919, 49959, 49139, 49999, 44922, 49998, 49999, 49999, 49946, 49939, 0, 49988, 49764, 49999, 49985, 49989, 46677, 41944, 49994, 49984, 48052, 49999, 49998, 49871, 49999, 49996, 49995, 49979, 49998, 42486, 49827, 49953, 49999, 49031, 0, 49834, 46471, 49889, 49917, 45530, 49999, 49982, 49729, 49552, 49995, 49999, 49990, 49957, 49992, 0, 49991, 49999, 49999, 49988, 43456, 4331, 49657, 49977, 49997, 49943, 49878, 49965, 49996, 49997, 48664, 49948, 49997, 49999, 48313, 49989, 49999, 49999, 49756, 49999, 49998, 49996]\n"
     ]
    }
   ],
   "source": [
    "sent_indices = sent_tokens.map(lambda x: [word_index[word] for word in x])\n",
    "print(f'Indieces len : {len(sent_indices[0])}') #len(sent_indices[0])\n",
    "print(f'Sentences : {sent_indices[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting postive and negatives to 1 and 0 respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = df.sentiment.map(lambda x: 1 if x == 'positive' else 0)\n",
    "target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weights Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "hidden_size = 100\n",
    "alpha, iteration = 0.01, 10\n",
    "\n",
    "weights_0_1 = 0.2*np.random.random((len(vocab),hidden_size)) - 0.1\n",
    "weights_1_2 = 0.2*np.random.random((hidden_size,1)) - 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural network to compute the sentiments from the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0, Accuracy: 0.50866\n",
      "Iteration: 1, Accuracy: 0.47844\n",
      "Iteration: 2, Accuracy: 0.42722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_186455/2337424581.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3, Accuracy: 0.3763\n",
      "Iteration: 4, Accuracy: 0.33978\n",
      "Iteration: 5, Accuracy: 0.32068\n",
      "Iteration: 6, Accuracy: 0.31636\n",
      "Iteration: 7, Accuracy: 0.32258\n",
      "Iteration: 8, Accuracy: 0.33352\n",
      "Iteration: 9, Accuracy: 0.34514\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "\n",
    "def neural_network(x,y):\n",
    "\n",
    "    global weights_0_1, weights_1_2 \n",
    "\n",
    "    # print(f'x {len(x)}')\n",
    "    layer_1 = sigmoid(np.sum(weights_0_1[x],axis=0))\n",
    "    # print(f'Layer 1 shape: {layer_1.shape}')\n",
    "    layer_2 = sigmoid(np.dot(layer_1,weights_1_2))\n",
    "    \n",
    "    layer_2_delta = layer_2 - y\n",
    "    # print(f'weights_1_2 shape: {weights_1_2.T.shape}')\n",
    "\n",
    "    layer_1_delta = layer_2_delta.dot(weights_1_2.T)  \n",
    "    # print(f'layer_1_delta shape: {layer_1_delta.shape}')\n",
    "\n",
    "    weights_1_2 -= np.outer(layer_1 , layer_2_delta) * alpha\n",
    "    weights_0_1[x] -= layer_1_delta * alpha\n",
    "\n",
    "    return layer_2\n",
    "\n",
    "correct , total = 0, 0\n",
    "for i in range(iteration):\n",
    "    for x,y in zip(sent_indices,target):\n",
    "        output = neural_network(x,y)\n",
    "\n",
    "        correct += 1 if np.abs(output) < 0.5 else 0\n",
    "        total += 1\n",
    "\n",
    "    print(f'Iteration: {i}, Accuracy: {correct/total}')\n",
    "    correct , total = 0, 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
