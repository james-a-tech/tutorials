{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skip-gram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>movie</td>\n",
       "      <td>was</td>\n",
       "      <td>boring</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>movie</td>\n",
       "      <td>actions</td>\n",
       "      <td>were</td>\n",
       "      <td>very</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>movie</td>\n",
       "      <td>was</td>\n",
       "      <td>good</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>movie</td>\n",
       "      <td>story</td>\n",
       "      <td>was</td>\n",
       "      <td>very</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0        1       2     3     4\n",
       "0  movie      was  boring  None  None\n",
       "1  movie  actions    were  very  good\n",
       "2  movie      was    good  None  None\n",
       "3  movie    story     was  very   bad"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "corpus = [\n",
    "    \"Movie was boring\",\n",
    "    \"Movie actions were very good\",\n",
    "    \"Movie was good\",\n",
    "    \"Movie story was very bad\"\n",
    "]\n",
    "\n",
    "# Preprocessing: \n",
    "##  tokenize the sentences\n",
    "def tokenize_corpus(corpus):\n",
    "    tokens = [sentence.lower().split() for sentence in corpus]\n",
    "    return tokens\n",
    "\n",
    "tokenized_corpus = tokenize_corpus(corpus)\n",
    "\n",
    "pd.DataFrame(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unique set of words in the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'actions', 'bad', 'boring', 'good', 'movie', 'story', 'very', 'was', 'were'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build vocabulary and mappings\n",
    "vocab = set()\n",
    "for sentence in tokenized_corpus:\n",
    "    vocab.update(sentence)\n",
    "\n",
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign a unique index to each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bad</th>\n",
       "      <th>was</th>\n",
       "      <th>story</th>\n",
       "      <th>good</th>\n",
       "      <th>boring</th>\n",
       "      <th>movie</th>\n",
       "      <th>were</th>\n",
       "      <th>actions</th>\n",
       "      <th>very</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bad  was  story  good  boring  movie  were  actions  very\n",
       "0    0    1      2     3       4      5     6        7     8"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_index = {word: i for i, word in enumerate(vocab)}\n",
    "index_to_word = {i: word for word, i in word_to_index.items()}\n",
    "vocab_size = len(word_to_index)\n",
    "\n",
    "pd.DataFrame([word_to_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Define target (input) and surrounding words (output) for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('movie', 'was'),\n",
       " ('was', 'movie'),\n",
       " ('was', 'boring'),\n",
       " ('boring', 'was'),\n",
       " ('movie', 'actions'),\n",
       " ('actions', 'movie'),\n",
       " ('actions', 'were'),\n",
       " ('were', 'actions'),\n",
       " ('were', 'very'),\n",
       " ('very', 'were'),\n",
       " ('very', 'good'),\n",
       " ('good', 'very'),\n",
       " ('movie', 'was'),\n",
       " ('was', 'movie'),\n",
       " ('was', 'good'),\n",
       " ('good', 'was'),\n",
       " ('movie', 'story'),\n",
       " ('story', 'movie'),\n",
       " ('story', 'was'),\n",
       " ('was', 'story'),\n",
       " ('was', 'very'),\n",
       " ('very', 'was'),\n",
       " ('very', 'bad'),\n",
       " ('bad', 'very')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = []\n",
    "\n",
    "for sentence in tokenized_corpus:\n",
    "    for index, word in enumerate(sentence):\n",
    "        start = max(0,index -1)\n",
    "        end = min(len(sentence),index + 2)\n",
    "        for i in range( start,end):\n",
    "            if i == index:\n",
    "                continue\n",
    "            training_data.append((word,sentence[i]))\n",
    "training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating training matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.558863</td>\n",
       "      <td>-0.450077</td>\n",
       "      <td>-0.482045</td>\n",
       "      <td>-0.210383</td>\n",
       "      <td>0.743571</td>\n",
       "      <td>0.972926</td>\n",
       "      <td>0.246690</td>\n",
       "      <td>-0.276175</td>\n",
       "      <td>0.608900</td>\n",
       "      <td>-0.107225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.676004</td>\n",
       "      <td>0.350670</td>\n",
       "      <td>-0.296408</td>\n",
       "      <td>-0.220011</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>-0.859058</td>\n",
       "      <td>0.622075</td>\n",
       "      <td>-0.979189</td>\n",
       "      <td>0.939077</td>\n",
       "      <td>0.909042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>0.323528</td>\n",
       "      <td>-0.420377</td>\n",
       "      <td>-0.590993</td>\n",
       "      <td>-0.622760</td>\n",
       "      <td>0.835336</td>\n",
       "      <td>-0.384069</td>\n",
       "      <td>0.281857</td>\n",
       "      <td>0.451137</td>\n",
       "      <td>0.923902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.501703</td>\n",
       "      <td>-0.681849</td>\n",
       "      <td>0.735308</td>\n",
       "      <td>0.875643</td>\n",
       "      <td>0.901984</td>\n",
       "      <td>0.179165</td>\n",
       "      <td>0.631896</td>\n",
       "      <td>0.649565</td>\n",
       "      <td>0.855368</td>\n",
       "      <td>0.282343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.606698</td>\n",
       "      <td>0.967331</td>\n",
       "      <td>-0.703657</td>\n",
       "      <td>0.702238</td>\n",
       "      <td>0.823197</td>\n",
       "      <td>0.116379</td>\n",
       "      <td>-0.065489</td>\n",
       "      <td>-0.167417</td>\n",
       "      <td>-0.413385</td>\n",
       "      <td>0.512630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.367456</td>\n",
       "      <td>-0.202791</td>\n",
       "      <td>0.935990</td>\n",
       "      <td>0.072731</td>\n",
       "      <td>0.740566</td>\n",
       "      <td>0.886563</td>\n",
       "      <td>-0.167660</td>\n",
       "      <td>0.467634</td>\n",
       "      <td>-0.701546</td>\n",
       "      <td>0.039228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.010358</td>\n",
       "      <td>0.037167</td>\n",
       "      <td>0.924954</td>\n",
       "      <td>-0.352810</td>\n",
       "      <td>0.400363</td>\n",
       "      <td>-0.734969</td>\n",
       "      <td>-0.260772</td>\n",
       "      <td>0.638162</td>\n",
       "      <td>-0.341110</td>\n",
       "      <td>-0.021667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.985502</td>\n",
       "      <td>0.220966</td>\n",
       "      <td>0.842141</td>\n",
       "      <td>0.888686</td>\n",
       "      <td>0.498978</td>\n",
       "      <td>0.366570</td>\n",
       "      <td>0.019107</td>\n",
       "      <td>0.015352</td>\n",
       "      <td>-0.359787</td>\n",
       "      <td>0.912854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.763074</td>\n",
       "      <td>-0.149559</td>\n",
       "      <td>-0.809394</td>\n",
       "      <td>0.162321</td>\n",
       "      <td>-0.348835</td>\n",
       "      <td>0.034970</td>\n",
       "      <td>-0.334681</td>\n",
       "      <td>-0.794619</td>\n",
       "      <td>-0.745083</td>\n",
       "      <td>0.911792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.558863 -0.450077 -0.482045 -0.210383  0.743571  0.972926  0.246690   \n",
       "1  0.676004  0.350670 -0.296408 -0.220011  0.663800 -0.859058  0.622075   \n",
       "2  0.005383  0.323528 -0.420377 -0.590993 -0.622760  0.835336 -0.384069   \n",
       "3 -0.501703 -0.681849  0.735308  0.875643  0.901984  0.179165  0.631896   \n",
       "4  0.606698  0.967331 -0.703657  0.702238  0.823197  0.116379 -0.065489   \n",
       "5 -0.367456 -0.202791  0.935990  0.072731  0.740566  0.886563 -0.167660   \n",
       "6  0.010358  0.037167  0.924954 -0.352810  0.400363 -0.734969 -0.260772   \n",
       "7  0.985502  0.220966  0.842141  0.888686  0.498978  0.366570  0.019107   \n",
       "8  0.763074 -0.149559 -0.809394  0.162321 -0.348835  0.034970 -0.334681   \n",
       "\n",
       "          7         8         9  \n",
       "0 -0.276175  0.608900 -0.107225  \n",
       "1 -0.979189  0.939077  0.909042  \n",
       "2  0.281857  0.451137  0.923902  \n",
       "3  0.649565  0.855368  0.282343  \n",
       "4 -0.167417 -0.413385  0.512630  \n",
       "5  0.467634 -0.701546  0.039228  \n",
       "6  0.638162 -0.341110 -0.021667  \n",
       "7  0.015352 -0.359787  0.912854  \n",
       "8 -0.794619 -0.745083  0.911792  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "embedding_dim = 10\n",
    "learning_rate = 0.001\n",
    "epochs = 10000\n",
    "\n",
    "# Weight initialization\n",
    "W1 = np.random.uniform(-1, 1, (vocab_size, embedding_dim))  # Input to hidden weights\n",
    "W2 = np.random.uniform(-1, 1, (embedding_dim, vocab_size))  # Hidden to output weights\n",
    "\n",
    "pd.DataFrame(W1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and generating word embeddings without negative sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000, Loss: 1.7347\n",
      "Epoch 2000, Loss: 0.5940\n",
      "Epoch 3000, Loss: 0.3327\n",
      "Epoch 4000, Loss: 0.2250\n",
      "Epoch 5000, Loss: 0.1676\n",
      "Epoch 6000, Loss: 0.1325\n",
      "Epoch 7000, Loss: 0.1089\n",
      "Epoch 8000, Loss: 0.0921\n",
      "Epoch 9000, Loss: 0.0795\n",
      "Epoch 10000, Loss: 0.0698\n"
     ]
    }
   ],
   "source": [
    "# One-hot encoding function\n",
    "def one_hot_vector(word, word_to_index):\n",
    "    one_hot = np.zeros(vocab_size)\n",
    "    one_hot[word_to_index[word]] = 1\n",
    "    return one_hot\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    loss = 0\n",
    "    for target, context in training_data:\n",
    "        # Forward pass\n",
    "        context_vectors = np.sum([one_hot_vector(target, word_to_index)], axis=0)\n",
    "        h = np.dot(context_vectors, W1)  # Hidden layer\n",
    "        u = np.dot(h, W2)  # Output layer\n",
    "        y_pred = np.exp(u) / np.sum(np.exp(u)) # Softmax activation\n",
    "        \n",
    "        # Calculate loss (cross-entropy)\n",
    "        target_one_hot = one_hot_vector(target, word_to_index)\n",
    "        loss += -np.sum(target_one_hot * np.log(y_pred + 1e-8))\n",
    "\n",
    "        # Backpropagation\n",
    "        e = y_pred - target_one_hot\n",
    "        dW2 = np.outer(h, e)\n",
    "        dW1 = np.outer(context_vectors, np.dot(W2, e))\n",
    "\n",
    "        # Update weights\n",
    "        W1 -= learning_rate * dW1\n",
    "        W2 -= learning_rate * dW2\n",
    "\n",
    "    # Print loss every 1000 epochs\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(f'Epoch {epoch + 1}, Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bad</th>\n",
       "      <th>was</th>\n",
       "      <th>story</th>\n",
       "      <th>good</th>\n",
       "      <th>boring</th>\n",
       "      <th>movie</th>\n",
       "      <th>were</th>\n",
       "      <th>actions</th>\n",
       "      <th>very</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.735443</td>\n",
       "      <td>-0.824483</td>\n",
       "      <td>-0.585991</td>\n",
       "      <td>0.031183</td>\n",
       "      <td>1.202295</td>\n",
       "      <td>-1.610770</td>\n",
       "      <td>-0.690566</td>\n",
       "      <td>1.218512</td>\n",
       "      <td>1.376613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.145329</td>\n",
       "      <td>0.340800</td>\n",
       "      <td>-0.655562</td>\n",
       "      <td>-1.472839</td>\n",
       "      <td>0.556116</td>\n",
       "      <td>0.798795</td>\n",
       "      <td>-0.479428</td>\n",
       "      <td>1.018777</td>\n",
       "      <td>-0.124884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.167133</td>\n",
       "      <td>-0.927087</td>\n",
       "      <td>-0.513141</td>\n",
       "      <td>1.066024</td>\n",
       "      <td>-1.042191</td>\n",
       "      <td>1.571263</td>\n",
       "      <td>0.984312</td>\n",
       "      <td>0.698056</td>\n",
       "      <td>-0.331620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.021334</td>\n",
       "      <td>0.030539</td>\n",
       "      <td>-1.136659</td>\n",
       "      <td>1.215518</td>\n",
       "      <td>-0.762876</td>\n",
       "      <td>0.060400</td>\n",
       "      <td>-0.257658</td>\n",
       "      <td>0.630519</td>\n",
       "      <td>1.177853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.977032</td>\n",
       "      <td>-0.159515</td>\n",
       "      <td>-1.660993</td>\n",
       "      <td>1.309154</td>\n",
       "      <td>1.258262</td>\n",
       "      <td>0.921352</td>\n",
       "      <td>-0.046623</td>\n",
       "      <td>-0.112564</td>\n",
       "      <td>0.196002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.732744</td>\n",
       "      <td>-1.786758</td>\n",
       "      <td>1.279250</td>\n",
       "      <td>-0.665958</td>\n",
       "      <td>-0.739589</td>\n",
       "      <td>1.224908</td>\n",
       "      <td>-0.237851</td>\n",
       "      <td>0.652473</td>\n",
       "      <td>0.408416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.803412</td>\n",
       "      <td>0.314957</td>\n",
       "      <td>0.227222</td>\n",
       "      <td>0.744522</td>\n",
       "      <td>0.608762</td>\n",
       "      <td>0.274491</td>\n",
       "      <td>-0.739552</td>\n",
       "      <td>-0.594229</td>\n",
       "      <td>-1.054363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.621141</td>\n",
       "      <td>-1.553057</td>\n",
       "      <td>-0.501898</td>\n",
       "      <td>0.806874</td>\n",
       "      <td>-0.430438</td>\n",
       "      <td>0.020153</td>\n",
       "      <td>1.641897</td>\n",
       "      <td>0.638145</td>\n",
       "      <td>-2.071297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.270751</td>\n",
       "      <td>1.468846</td>\n",
       "      <td>-0.075014</td>\n",
       "      <td>0.712767</td>\n",
       "      <td>0.115631</td>\n",
       "      <td>0.219112</td>\n",
       "      <td>-0.716025</td>\n",
       "      <td>-1.206140</td>\n",
       "      <td>-0.048304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.501684</td>\n",
       "      <td>0.268338</td>\n",
       "      <td>0.378241</td>\n",
       "      <td>0.669135</td>\n",
       "      <td>1.112098</td>\n",
       "      <td>0.655460</td>\n",
       "      <td>-1.350527</td>\n",
       "      <td>1.602655</td>\n",
       "      <td>0.157360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        bad       was     story      good    boring     movie      were  \\\n",
       "0  0.735443 -0.824483 -0.585991  0.031183  1.202295 -1.610770 -0.690566   \n",
       "1 -0.145329  0.340800 -0.655562 -1.472839  0.556116  0.798795 -0.479428   \n",
       "2 -1.167133 -0.927087 -0.513141  1.066024 -1.042191  1.571263  0.984312   \n",
       "3 -0.021334  0.030539 -1.136659  1.215518 -0.762876  0.060400 -0.257658   \n",
       "4  0.977032 -0.159515 -1.660993  1.309154  1.258262  0.921352 -0.046623   \n",
       "5  1.732744 -1.786758  1.279250 -0.665958 -0.739589  1.224908 -0.237851   \n",
       "6  0.803412  0.314957  0.227222  0.744522  0.608762  0.274491 -0.739552   \n",
       "7  0.621141 -1.553057 -0.501898  0.806874 -0.430438  0.020153  1.641897   \n",
       "8  0.270751  1.468846 -0.075014  0.712767  0.115631  0.219112 -0.716025   \n",
       "9 -0.501684  0.268338  0.378241  0.669135  1.112098  0.655460 -1.350527   \n",
       "\n",
       "    actions      very  \n",
       "0  1.218512  1.376613  \n",
       "1  1.018777 -0.124884  \n",
       "2  0.698056 -0.331620  \n",
       "3  0.630519  1.177853  \n",
       "4 -0.112564  0.196002  \n",
       "5  0.652473  0.408416  \n",
       "6 -0.594229 -1.054363  \n",
       "7  0.638145 -2.071297  \n",
       "8 -1.206140 -0.048304  \n",
       "9  1.602655  0.157360  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_dict = {}\n",
    "for word, idx in word_to_index.items():\n",
    "    embed_dict[word] = W1[idx]\n",
    "    # print(f'Word: {word}, Embedding: {W1[idx]}')\n",
    "\n",
    "import pandas as pd\n",
    "pd.DataFrame(embed_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the Euclidian distances b/w the word embeding to see the similarity b/w them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('boring', -0.0),\n",
       " ('bad', -3.352469543609894),\n",
       " ('was', -3.434140047111468),\n",
       " ('actions', -3.6848492192246494),\n",
       " ('very', -3.688984247207017),\n",
       " ('good', -3.9946150357586943),\n",
       " ('story', -4.290580058146138),\n",
       " ('movie', -4.470671911570958),\n",
       " ('were', -4.88266343835967)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "def similar(target='beautiful'):\n",
    "    target_index = word_to_index[target] \n",
    "    scores = Counter() \n",
    "    for word,index in word_to_index.items(): \n",
    "        raw_difference = W1[index] - (W1[target_index]) \n",
    "        squared_difference = raw_difference * raw_difference \n",
    "        scores[word] = -math.sqrt(sum(squared_difference)) \n",
    "\n",
    "    return scores.most_common(10)\n",
    "\n",
    "similar('boring')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
