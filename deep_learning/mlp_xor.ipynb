{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain backprogration also here for MLP\n",
    "\n",
    "Key point: How do you calculate the deltas for layer_1? First, do the obvious: multiply the output delta by each weight attached to it. This gives a weighting of how much each weight contributed to that error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x1  x2  y\n",
       "0   0   0  0\n",
       "1   0   1  1\n",
       "2   1   0  1\n",
       "3   1   1  0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "inputs = np.array([[ 0, 0],\n",
    "                    [ 0, 1],\n",
    "                    [ 1, 0],\n",
    "                    [ 1, 1] ] )\n",
    "ouputs = np.array( [ 0, 1, 1, 0  ] )\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'x1': inputs[:, 0],\n",
    "    'x2': inputs[:, 1],\n",
    "    'y': ouputs\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weightes\n",
      "[[0.40768703 0.05536604 0.78853488 0.28730518]\n",
      " [0.45035059 0.30391231 0.52639952 0.62381221]]\n",
      "[[0.77677546]\n",
      " [0.68624165]\n",
      " [0.98093886]\n",
      " [0.60081609]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(40)\n",
    "\n",
    "def relu(x):\n",
    "    return (x > 0) * x\n",
    "\n",
    "def relu2deriv(output):\n",
    "    return output>0\n",
    "\n",
    "streetlights = np.array([[ 0, 0 ],\n",
    "                         [ 0, 1 ],\n",
    "                         [ 1, 0 ],\n",
    "                         [ 1, 1 ] ] )\n",
    "walk_vs_stop = np.array([[ 0, 1, 1, 0]]).T\n",
    "\n",
    "alpha = 0.001\n",
    "hidden_size = 4\n",
    "\n",
    "# weights_0_1 = np.array([ [1,1],[1,1] ] , dtype=np.float64) # np.random.random((2,hidden_size))\n",
    "# weights_1_2 = np.array([ [ 1 ],[1] ] , dtype=np.float64) #np.random.random((hidden_size,1)) \n",
    "\n",
    "weights_0_1 = np.random.random((2,hidden_size))\n",
    "weights_1_2 = np.random.random((hidden_size,1))\n",
    "\n",
    "print(\"Weightes\")\n",
    "print(weights_0_1)\n",
    "print(weights_1_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c5bd3d7ce0a443085f78feef50b4c3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'mode': 'markers+text',\n",
       "              'text': array([0., 1., 1., 0.]),\n",
       "              'textfont': {'color': 'red', 'family': 'sans serif', 'size': 20},\n",
       "              'textposition': 'middle right',\n",
       "              'type': 'scatter',\n",
       "              'uid': '4b2d8030-89ec-4ea4-a225-46c17a901a7e',\n",
       "              'x': array([0, 0, 1, 1]),\n",
       "              'y': array([0, 1, 0, 1])}],\n",
       "    'layout': {'template': '...'}\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.graph_objects as go    \n",
    "\n",
    "data_fig = go.FigureWidget()\n",
    "data_fig.add_scatter(mode=\"markers+text\", x=streetlights[:,0], y=streetlights[:,1], text=walk_vs_stop[:,0],\n",
    "                    textposition='middle right'\n",
    "                    ,  textfont=dict(\n",
    "                        family=\"sans serif\",\n",
    "                        size=20,\n",
    "                        color=\"red\"\n",
    "                    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Iteration: 0 *************\n",
      "Layer 0 = [[0 0]]\n",
      "Layer 1 = [[0. 0. 0. 0.]]\n",
      "Layer 2 = [[0.]]\n",
      "Output = [[0]]\n",
      "==============================================\n",
      "Layer 0 = [[0 1]]\n",
      "Layer 1 = [[0.42714734 0.28325148 0.49718934 0.60597069]]\n",
      "Layer 2 = [[1.32940877]]\n",
      "Output = [[1]]\n",
      "==============================================\n",
      "Layer 0 = [[1 0]]\n",
      "Layer 1 = [[0.38560359 0.03570219 0.76073437 0.27032504]]\n",
      "Layer 2 = [[1.18642825]]\n",
      "Output = [[1]]\n",
      "==============================================\n",
      "Layer 0 = [[1 1]]\n",
      "Layer 1 = [[0.81236306 0.31860499 1.25743731 0.87599964]]\n",
      "Layer 2 = [[2.5141093]]\n",
      "Output = [[0]]\n",
      "==============================================\n",
      "Error:6.464011182749799\n",
      "[[0.         0.         0.         0.        ]\n",
      " [0.42714734 0.28325148 0.49718934 0.60597069]\n",
      " [0.38560359 0.03570219 0.76073437 0.27032504]\n",
      " [0.81236306 0.31860499 1.25743731 0.87599964]]\n",
      "********** Iteration: 1 *************\n",
      "Layer 0 = [[0 0]]\n",
      "Layer 1 = [[0. 0. 0. 0.]]\n",
      "Layer 2 = [[0.]]\n",
      "Output = [[0]]\n",
      "==============================================\n",
      "Layer 0 = [[0 1]]\n",
      "Layer 1 = [[0.42500962 0.28132957 0.49450866 0.60433889]]\n",
      "Layer 2 = [[1.31862906]]\n",
      "Output = [[1]]\n",
      "==============================================\n",
      "Layer 0 = [[1 0]]\n",
      "Layer 1 = [[0.38357341 0.03387695 0.75818855 0.26877536]]\n",
      "Layer 2 = [[1.17620416]]\n",
      "Output = [[1]]\n",
      "==============================================\n",
      "Layer 0 = [[1 1]]\n",
      "Layer 1 = [[0.80821207 0.31487249 1.25223233 0.87283142]]\n",
      "Layer 2 = [[2.49318916]]\n",
      "Output = [[0]]\n",
      "==============================================\n",
      "Error:6.348564556195912\n",
      "[[0.         0.         0.         0.        ]\n",
      " [0.42500962 0.28132957 0.49450866 0.60433889]\n",
      " [0.38357341 0.03387695 0.75818855 0.26877536]\n",
      " [0.80821207 0.31487249 1.25223233 0.87283142]]\n",
      "********** Iteration: 2 *************\n",
      "Layer 0 = [[0 0]]\n",
      "Layer 1 = [[0. 0. 0. 0.]]\n",
      "Layer 2 = [[0.]]\n",
      "Output = [[0]]\n",
      "==============================================\n",
      "Layer 0 = [[0 1]]\n",
      "Layer 1 = [[0.42290205 0.27943161 0.49186758 0.60273215]]\n",
      "Layer 2 = [[1.30804866]]\n",
      "Output = [[1]]\n",
      "==============================================\n",
      "Layer 0 = [[1 0]]\n",
      "Layer 1 = [[0.38157264 0.03207516 0.75568131 0.26725007]]\n",
      "Layer 2 = [[1.16617026]]\n",
      "Output = [[1]]\n",
      "==============================================\n",
      "Layer 0 = [[1 1]]\n",
      "Layer 1 = [[0.80412023 0.31118707 1.24710499 0.86971232]]\n",
      "Layer 2 = [[2.47265598]]\n",
      "Output = [[0]]\n",
      "==============================================\n",
      "Error:6.236534125131824\n",
      "[[0.         0.         0.         0.        ]\n",
      " [0.42290205 0.27943161 0.49186758 0.60273215]\n",
      " [0.38157264 0.03207516 0.75568131 0.26725007]\n",
      " [0.80412023 0.31118707 1.24710499 0.86971232]]\n",
      "********** Iteration: 3 *************\n",
      "Layer 0 = [[0 0]]\n",
      "Layer 1 = [[0. 0. 0. 0.]]\n",
      "Layer 2 = [[0.]]\n",
      "Output = [[0]]\n",
      "==============================================\n",
      "Layer 0 = [[0 1]]\n",
      "Layer 1 = [[0.42082394 0.2775571  0.48926518 0.60114989]]\n",
      "Layer 2 = [[1.29766209]]\n",
      "Output = [[1]]\n",
      "==============================================\n",
      "Layer 0 = [[1 0]]\n",
      "Layer 1 = [[0.37960061 0.03029631 0.75321175 0.2657486 ]]\n",
      "Layer 2 = [[1.15632132]]\n",
      "Output = [[1]]\n",
      "==============================================\n",
      "Layer 0 = [[1 1]]\n",
      "Layer 1 = [[0.80008621 0.30754773 1.2420535  0.86664118]]\n",
      "Layer 2 = [[2.45249913]]\n",
      "Output = [[0]]\n",
      "==============================================\n",
      "Error:6.127791055445071\n",
      "[[0.         0.         0.         0.        ]\n",
      " [0.42082394 0.2775571  0.48926518 0.60114989]\n",
      " [0.37960061 0.03029631 0.75321175 0.2657486 ]\n",
      " [0.80008621 0.30754773 1.2420535  0.86664118]]\n",
      "********** Iteration: 4 *************\n",
      "Layer 0 = [[0 0]]\n",
      "Layer 1 = [[0. 0. 0. 0.]]\n",
      "Layer 2 = [[0.]]\n",
      "Output = [[0]]\n",
      "==============================================\n",
      "Layer 0 = [[0 1]]\n",
      "Layer 1 = [[0.41877464 0.27570552 0.48670058 0.59959153]]\n",
      "Layer 2 = [[1.28746407]]\n",
      "Output = [[1]]\n",
      "==============================================\n",
      "Layer 0 = [[1 0]]\n",
      "Layer 1 = [[0.37765668 0.02853992 0.75077901 0.26427039]]\n",
      "Layer 2 = [[1.14665228]]\n",
      "Output = [[1]]\n",
      "==============================================\n",
      "Layer 0 = [[1 1]]\n",
      "Layer 1 = [[0.79610872 0.30395351 1.23707612 0.86361688]]\n",
      "Layer 2 = [[2.43270836]]\n",
      "Output = [[0]]\n",
      "==============================================\n",
      "Error:6.0222124614619865\n",
      "[[0.         0.         0.         0.        ]\n",
      " [0.41877464 0.27570552 0.48670058 0.59959153]\n",
      " [0.37765668 0.02853992 0.75077901 0.26427039]\n",
      " [0.79610872 0.30395351 1.23707612 0.86361688]]\n",
      "********** Iteration: 5 *************\n",
      "Layer 0 = [[0 0]]\n",
      "Layer 1 = [[0. 0. 0. 0.]]\n",
      "Layer 2 = [[0.]]\n",
      "Output = [[0]]\n",
      "==============================================\n",
      "Layer 0 = [[0 1]]\n",
      "Layer 1 = [[0.41675351 0.27387642 0.48417291 0.59805652]]\n",
      "Layer 2 = [[1.27744949]]\n",
      "Output = [[1]]\n",
      "==============================================\n",
      "Layer 0 = [[1 0]]\n",
      "Layer 1 = [[0.37574021 0.02680552 0.74838224 0.26281489]]\n",
      "Layer 2 = [[1.13715827]]\n",
      "Output = [[1]]\n",
      "==============================================\n",
      "Layer 0 = [[1 1]]\n",
      "Layer 1 = [[0.79218649 0.30040348 1.23217117 0.86063835]]\n",
      "Layer 2 = [[2.41327381]]\n",
      "Output = [[0]]\n",
      "==============================================\n",
      "Error:5.9196810809480835\n",
      "[[0.         0.         0.         0.        ]\n",
      " [0.41675351 0.27387642 0.48417291 0.59805652]\n",
      " [0.37574021 0.02680552 0.74838224 0.26281489]\n",
      " [0.79218649 0.30040348 1.23217117 0.86063835]]\n",
      "********** Iteration: 6 *************\n",
      "Layer 0 = [[0 0]]\n",
      "Layer 1 = [[0. 0. 0. 0.]]\n",
      "Layer 2 = [[0.]]\n",
      "Output = [[0]]\n",
      "==============================================\n",
      "Layer 0 = [[0 1]]\n",
      "Layer 1 = [[0.41475992 0.27206933 0.48168135 0.59654433]]\n",
      "Layer 2 = [[1.26761344]]\n",
      "Output = [[1]]\n",
      "==============================================\n",
      "Layer 0 = [[1 0]]\n",
      "Layer 1 = [[0.3738506  0.02509267 0.74602064 0.2613816 ]]\n",
      "Layer 2 = [[1.12783461]]\n",
      "Output = [[1]]\n",
      "==============================================\n",
      "Layer 0 = [[1 1]]\n",
      "Layer 1 = [[0.78831831 0.29689672 1.22733702 0.85770454]]\n",
      "Layer 2 = [[2.39418594]]\n",
      "Output = [[0]]\n",
      "==============================================\n",
      "Error:5.820084970586756\n",
      "[[0.         0.         0.         0.        ]\n",
      " [0.41475992 0.27206933 0.48168135 0.59654433]\n",
      " [0.3738506  0.02509267 0.74602064 0.2613816 ]\n",
      " [0.78831831 0.29689672 1.22733702 0.85770454]]\n",
      "********** Iteration: 7 *************\n",
      "Layer 0 = [[0 0]]\n",
      "Layer 1 = [[0. 0. 0. 0.]]\n",
      "Layer 2 = [[0.]]\n",
      "Output = [[0]]\n",
      "==============================================\n",
      "Layer 0 = [[0 1]]\n",
      "Layer 1 = [[0.41279328 0.2702838  0.47922509 0.59505445]]\n",
      "Layer 2 = [[1.25795118]]\n",
      "Output = [[1]]\n",
      "==============================================\n",
      "Layer 0 = [[1 0]]\n",
      "Layer 1 = [[0.37198727 0.02340092 0.74369341 0.25996999]]\n",
      "Layer 2 = [[1.11867677]]\n",
      "Output = [[1]]\n",
      "==============================================\n",
      "Layer 0 = [[1 1]]\n",
      "Layer 1 = [[0.78450301 0.29343236 1.22257209 0.85481443]]\n",
      "Layer 2 = [[2.37543559]]\n",
      "Output = [[0]]\n",
      "==============================================\n",
      "Error:5.723317220476894\n",
      "[[0.         0.         0.         0.        ]\n",
      " [0.41279328 0.2702838  0.47922509 0.59505445]\n",
      " [0.37198727 0.02340092 0.74369341 0.25996999]\n",
      " [0.78450301 0.29343236 1.22257209 0.85481443]]\n",
      "********** Iteration: 8 *************\n",
      "Layer 0 = [[0 0]]\n",
      "Layer 1 = [[0. 0. 0. 0.]]\n",
      "Layer 2 = [[0.]]\n",
      "Output = [[0]]\n",
      "==============================================\n",
      "Layer 0 = [[0 1]]\n",
      "Layer 1 = [[0.410853   0.26851939 0.47680335 0.59358636]]\n",
      "Layer 2 = [[1.24845815]]\n",
      "Output = [[1]]\n",
      "==============================================\n",
      "Layer 0 = [[1 0]]\n",
      "Layer 1 = [[0.37014964 0.02172985 0.74139979 0.25857959]]\n",
      "Layer 2 = [[1.10968038]]\n",
      "Output = [[1]]\n",
      "==============================================\n",
      "Layer 0 = [[1 1]]\n",
      "Layer 1 = [[0.78073945 0.29000954 1.21787485 0.85196704]]\n",
      "Layer 2 = [[2.35701388]]\n",
      "Output = [[0]]\n",
      "==============================================\n",
      "Error:5.629275686305757\n",
      "[[0.         0.         0.         0.        ]\n",
      " [0.410853   0.26851939 0.47680335 0.59358636]\n",
      " [0.37014964 0.02172985 0.74139979 0.25857959]\n",
      " [0.78073945 0.29000954 1.21787485 0.85196704]]\n",
      "********** Iteration: 9 *************\n",
      "Layer 0 = [[0 0]]\n",
      "Layer 1 = [[0. 0. 0. 0.]]\n",
      "Layer 2 = [[0.]]\n",
      "Output = [[0]]\n",
      "==============================================\n",
      "Layer 0 = [[0 1]]\n",
      "Layer 1 = [[0.40893852 0.26677568 0.47441538 0.59213959]]\n",
      "Layer 2 = [[1.23912992]]\n",
      "Output = [[1]]\n",
      "==============================================\n",
      "Layer 0 = [[1 0]]\n",
      "Layer 1 = [[0.36833716 0.02007903 0.73913904 0.25720992]]\n",
      "Layer 2 = [[1.10084124]]\n",
      "Output = [[1]]\n",
      "==============================================\n",
      "Layer 0 = [[1 1]]\n",
      "Layer 1 = [[0.77702651 0.28662742 1.21324382 0.84916143]]\n",
      "Layer 2 = [[2.33891228]]\n",
      "Output = [[0]]\n",
      "==============================================\n",
      "Error:5.537862737959342\n",
      "[[0.         0.         0.         0.        ]\n",
      " [0.40893852 0.26677568 0.47441538 0.59213959]\n",
      " [0.36833716 0.02007903 0.73913904 0.25720992]\n",
      " [0.77702651 0.28662742 1.21324382 0.84916143]]\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(10):\n",
    "    layer_2_error = 0\n",
    "\n",
    "    array = np.empty((4,hidden_size))\n",
    "\n",
    "    print(f\"********** Iteration: {iteration} *************\")\n",
    "    for i in range(len(streetlights)):\n",
    "        # forward pass\n",
    "        layer_0 = streetlights[i:i+1]\n",
    "        print(f'Layer 0 = {layer_0}')\n",
    "        layer_1 = relu(np.dot(layer_0,weights_0_1))\n",
    "        print(f'Layer 1 = {layer_1}')\n",
    "        layer_2 = np.dot(layer_1,weights_1_2)\n",
    "        print(f'Layer 2 = {layer_2}')\n",
    "\n",
    "        array[i] = layer_1\n",
    "        # backward pass\n",
    "        layer_2_error += np.sum((layer_2 - walk_vs_stop[i:i+1]) ** 2)\n",
    "        \n",
    "        layer_2_delta = (layer_2 - walk_vs_stop[i:i+1])\n",
    "        layer_1_delta = layer_2_delta.dot(weights_1_2.T) * relu2deriv(layer_1)\n",
    "\n",
    "        # layer_1_delta = layer_1 - layer_2\n",
    "        # weight updating\n",
    "        weights_1_2 -= alpha * layer_1.T.dot(layer_2_delta)\n",
    "        weights_0_1 -= alpha * layer_0.T.dot(layer_1_delta)\n",
    "        print(f'Output = {walk_vs_stop[i:i+1]}')\n",
    "        print(\"==============================================\")\n",
    "            \n",
    "    print(\"Error:\" + str(layer_2_error))\n",
    "    print(f'{array}')\n",
    "    \n",
    "    data_fig.data[0].x = array[:,0]\n",
    "    data_fig.data[0].y = array[:,1]\n",
    "\n",
    "    import time\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.2913239088494768\n",
      "Epoch 1000, Loss: 0.25013205911182146\n",
      "Epoch 2000, Loss: 0.2500839755180796\n",
      "Epoch 3000, Loss: 0.2500575150938403\n",
      "Epoch 4000, Loss: 0.2500415143068478\n",
      "Epoch 5000, Loss: 0.25003101962364\n",
      "Epoch 6000, Loss: 0.2500236895266624\n",
      "Epoch 7000, Loss: 0.25001833734402235\n",
      "Epoch 8000, Loss: 0.25001431284494097\n",
      "Epoch 9000, Loss: 0.2500112294597659\n",
      "Predictions:\n",
      "[[0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Helper functions\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_derivative(x):\n",
    "    return np.where(x > 0, 1, 0)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "def mse_loss(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "# XOR input and output\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "# Initialize parameters\n",
    "# np.random.seed(42)\n",
    "\n",
    "# Number of neurons in each layer\n",
    "input_neurons = 2\n",
    "hidden_neurons = 2\n",
    "output_neurons = 1\n",
    "\n",
    "# Weights and biases initialization\n",
    "weights_input_hidden = np.random.rand(input_neurons, hidden_neurons)\n",
    "weights_hidden_output = np.random.rand(hidden_neurons, output_neurons)\n",
    "bias_hidden = np.random.rand(1, hidden_neurons)\n",
    "bias_output = np.random.rand(1, output_neurons)\n",
    "\n",
    "# Training parameters\n",
    "learning_rate = 0.01\n",
    "epochs = 10000\n",
    "\n",
    "# Training the model\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass\n",
    "    hidden_layer_input = np.dot(X, weights_input_hidden) + bias_hidden\n",
    "    hidden_layer_output = relu(hidden_layer_input)\n",
    "    \n",
    "    output_layer_input = np.dot(hidden_layer_output, weights_hidden_output) + bias_output\n",
    "    output_layer_output = sigmoid(output_layer_input)\n",
    "    \n",
    "    # Compute the loss\n",
    "    loss = mse_loss(y, output_layer_output)\n",
    "    \n",
    "    # Backpropagation\n",
    "    error_output_layer = y - output_layer_output\n",
    "    d_output = error_output_layer * sigmoid_derivative(output_layer_output)\n",
    "    \n",
    "    error_hidden_layer = d_output.dot(weights_hidden_output.T)\n",
    "    d_hidden = error_hidden_layer * relu_derivative(hidden_layer_output)\n",
    "    \n",
    "    # Update weights and biases\n",
    "    weights_hidden_output += hidden_layer_output.T.dot(d_output) * learning_rate\n",
    "    bias_output += np.sum(d_output, axis=0, keepdims=True) * learning_rate\n",
    "    \n",
    "    weights_input_hidden += X.T.dot(d_hidden) * learning_rate\n",
    "    bias_hidden += np.sum(d_hidden, axis=0, keepdims=True) * learning_rate\n",
    "\n",
    "    # Optionally print the loss at certain intervals\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss}')\n",
    "\n",
    "# Making predictions\n",
    "hidden_layer_input = np.dot(X, weights_input_hidden) + bias_hidden\n",
    "hidden_layer_output = relu(hidden_layer_input)\n",
    "\n",
    "output_layer_input = np.dot(hidden_layer_output, weights_hidden_output) + bias_output\n",
    "output_layer_output = sigmoid(output_layer_input)\n",
    "\n",
    "print('Predictions:')\n",
    "print(np.round(output_layer_output))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implemented Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-12 15:11:48.125293: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-12 15:11:49.483227: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-12 15:11:54.367960: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-12 15:12:24.642153: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/james/HDD/OneDrive/Cloud/tutorials/.conda/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.5000 - loss: 0.6931\n",
      "Loss: 0.6931473016738892, Accuracy: 0.5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Predictions:\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "# XOR input and output\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer -> Hidden layer with 2 neurons and ReLU activation\n",
    "model.add(Dense(4, input_dim=2, activation='relu'))\n",
    "\n",
    "# Hidden layer -> Output layer with 1 neuron and sigmoid activation\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer=SGD(learning_rate=0.01), metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y, epochs=1000, verbose=0)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X, y)\n",
    "print(f'Loss: {loss}, Accuracy: {accuracy}')\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X)\n",
    "print('Predictions:')\n",
    "print(np.round(predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
