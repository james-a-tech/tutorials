{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain backprogration also here for MLP\n",
    "\n",
    "Key point: How do you calculate the deltas for layer_1? First, do the obvious: multiply the output delta by each weight attached to it. This gives a weighting of how much each weight contributed to that error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x1  x2  y\n",
       "0   0   0  0\n",
       "1   0   1  1\n",
       "2   1   0  1\n",
       "3   1   1  0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "inputs = np.array([[ 0, 0],\n",
    "                    [ 0, 1],\n",
    "                    [ 1, 0],\n",
    "                    [ 1, 1] ] )\n",
    "ouputs = np.array( [ 0, 1, 1, 0  ] )\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'x1': inputs[:, 0],\n",
    "    'x2': inputs[:, 1],\n",
    "    'y': ouputs\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weightes\n",
      "[[0.40768703 0.05536604 0.78853488 0.28730518]\n",
      " [0.45035059 0.30391231 0.52639952 0.62381221]]\n",
      "[[0.77677546]\n",
      " [0.68624165]\n",
      " [0.98093886]\n",
      " [0.60081609]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(40)\n",
    "\n",
    "def relu(x):\n",
    "    return (x > 0) * x\n",
    "\n",
    "def relu2deriv(output):\n",
    "    return output>0\n",
    "\n",
    "streetlights = np.array([[ 0, 0 ],\n",
    "                         [ 0, 1 ],\n",
    "                         [ 1, 0 ],\n",
    "                         [ 1, 1 ] ] )\n",
    "walk_vs_stop = np.array([[ 0, 1, 1, 0]]).T\n",
    "\n",
    "alpha = 0.001\n",
    "hidden_size = 4\n",
    "\n",
    "# weights_0_1 = np.array([ [1,1],[1,1] ] , dtype=np.float64) # np.random.random((2,hidden_size))\n",
    "# weights_1_2 = np.array([ [ 1 ],[1] ] , dtype=np.float64) #np.random.random((hidden_size,1)) \n",
    "\n",
    "weights_0_1 = np.random.random((2,hidden_size))\n",
    "weights_1_2 = np.random.random((hidden_size,1))\n",
    "\n",
    "print(\"Weightes\")\n",
    "print(weights_0_1)\n",
    "print(weights_1_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63804acf0cfe4efeab4ff5ce66ca4cb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'mode': 'markers+text',\n",
       "              'text': array([0., 1., 1., 0.]),\n",
       "              'textfont': {'color': 'red', 'family': 'sans serif', 'size': 20},\n",
       "              'textposition': 'middle right',\n",
       "              'type': 'scatter',\n",
       "              'uid': '3b765a11-aa8d-4a4c-9cde-fe8e94388cca',\n",
       "              'x': array([0, 0, 1, 1]),\n",
       "              'y': array([0, 1, 0, 1])}],\n",
       "    'layout': {'template': '...'}\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.graph_objects as go    \n",
    "\n",
    "data_fig = go.FigureWidget()\n",
    "data_fig.add_scatter(mode=\"markers+text\", x=streetlights[:,0], y=streetlights[:,1], text=walk_vs_stop[:,0],\n",
    "                    textposition='middle right'\n",
    "                    ,  textfont=dict(\n",
    "                        family=\"sans serif\",\n",
    "                        size=20,\n",
    "                        color=\"red\"\n",
    "                    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Iteration: 0 *************\n",
      "Layer 0 = [[0 0]]\n",
      "Layer 1 = [[0. 0. 0. 0.]]\n",
      "Layer 2 = [[0.]]\n",
      "Output = [[0]]\n",
      "==============================================\n",
      "Layer 0 = [[0 1]]\n",
      "Layer 1 = [[0.45035059 0.30391231 0.52639952 0.62381221]]\n",
      "Layer 2 = [[1.44954073]]\n",
      "Output = [[1]]\n",
      "==============================================\n",
      "Layer 0 = [[1 0]]\n",
      "Layer 1 = [[0.40768703 0.05536604 0.78853488 0.28730518]]\n",
      "Layer 2 = [[1.30044058]]\n",
      "Output = [[1]]\n",
      "==============================================\n",
      "Layer 0 = [[1 1]]\n",
      "Layer 1 = [[0.85745511 0.35876372 1.31419879 0.91066688]]\n",
      "Layer 2 = [[2.74725075]]\n",
      "Output = [[0]]\n",
      "==============================================\n",
      "Error:7.839738097962158\n",
      "[[0.         0.         0.         0.        ]\n",
      " [0.45035059 0.30391231 0.52639952 0.62381221]\n",
      " [0.40768703 0.05536604 0.78853488 0.28730518]\n",
      " [0.85745511 0.35876372 1.31419879 0.91066688]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Iteration: 1 *************\n",
      "Layer 0 = [[0 0]]\n",
      "Layer 1 = [[0. 0. 0. 0.]]\n",
      "Layer 2 = [[0.]]\n",
      "Output = [[0]]\n",
      "==============================================\n",
      "Layer 0 = [[0 1]]\n",
      "Layer 1 = [[0.44786829 0.30171895 0.52326497 0.62189254]]\n",
      "Layer 2 = [[1.43641408]]\n",
      "Output = [[1]]\n",
      "==============================================\n",
      "Layer 0 = [[1 0]]\n",
      "Layer 1 = [[0.40532061 0.05327505 0.78554665 0.28547517]]\n",
      "Layer 2 = [[1.28797664]]\n",
      "Output = [[1]]\n",
      "==============================================\n",
      "Layer 0 = [[1 1]]\n",
      "Layer 1 = [[0.85262821 0.35449776 1.30810406 0.90693464]]\n",
      "Layer 2 = [[2.72177605]]\n",
      "Output = [[0]]\n",
      "==============================================\n",
      "Error:7.6814526763526585\n",
      "[[0.         0.         0.         0.        ]\n",
      " [0.44786829 0.30171895 0.52326497 0.62189254]\n",
      " [0.40532061 0.05327505 0.78554665 0.28547517]\n",
      " [0.85262821 0.35449776 1.30810406 0.90693464]]\n",
      "********** Iteration: 2 *************\n",
      "Layer 0 = [[0 0]]\n",
      "Layer 1 = [[0. 0. 0. 0.]]\n",
      "Layer 2 = [[0.]]\n",
      "Output = [[0]]\n",
      "==============================================\n",
      "Layer 0 = [[0 1]]\n",
      "Layer 1 = [[0.4454244  0.29955567 0.52018111 0.62000507]]\n",
      "Layer 2 = [[1.42355511]]\n",
      "Output = [[1]]\n",
      "==============================================\n",
      "Layer 0 = [[1 0]]\n",
      "Layer 1 = [[0.40299168 0.0512135  0.78260786 0.28367654]]\n",
      "Layer 2 = [[1.27576821]]\n",
      "Output = [[1]]\n",
      "==============================================\n",
      "Layer 0 = [[1 1]]\n",
      "Layer 1 = [[0.84787663 0.35029087 1.30210871 0.9032655 ]]\n",
      "Layer 2 = [[2.69682067]]\n",
      "Output = [[0]]\n",
      "==============================================\n",
      "Error:7.528288744762883\n",
      "[[0.         0.         0.         0.        ]\n",
      " [0.4454244  0.29955567 0.52018111 0.62000507]\n",
      " [0.40299168 0.0512135  0.78260786 0.28367654]\n",
      " [0.84787663 0.35029087 1.30210871 0.9032655 ]]\n",
      "********** Iteration: 3 *************\n",
      "Layer 0 = [[0 0]]\n",
      "Layer 1 = [[0. 0. 0. 0.]]\n",
      "Layer 2 = [[0.]]\n",
      "Output = [[0]]\n",
      "==============================================\n",
      "Layer 0 = [[0 1]]\n",
      "Layer 1 = [[0.44301796 0.29742174 0.51714666 0.61814897]]\n",
      "Layer 2 = [[1.41095569]]\n",
      "Output = [[1]]\n",
      "==============================================\n",
      "Layer 0 = [[1 0]]\n",
      "Layer 1 = [[0.4006993  0.04918069 0.77971725 0.28190847]]\n",
      "Layer 2 = [[1.2638075]]\n",
      "Output = [[1]]\n",
      "==============================================\n",
      "Layer 0 = [[1 1]]\n",
      "Layer 1 = [[0.8431985  0.34614166 1.29621019 0.89965781]]\n",
      "Layer 2 = [[2.67236885]]\n",
      "Output = [[0]]\n",
      "==============================================\n",
      "Error:7.380034264106701\n",
      "[[0.         0.         0.         0.        ]\n",
      " [0.44301796 0.29742174 0.51714666 0.61814897]\n",
      " [0.4006993  0.04918069 0.77971725 0.28190847]\n",
      " [0.8431985  0.34614166 1.29621019 0.89965781]]\n",
      "********** Iteration: 4 *************\n",
      "Layer 0 = [[0 0]]\n",
      "Layer 1 = [[0. 0. 0. 0.]]\n",
      "Layer 2 = [[0.]]\n",
      "Output = [[0]]\n",
      "==============================================\n",
      "Layer 0 = [[0 1]]\n",
      "Layer 1 = [[0.44064803 0.29531648 0.51416037 0.61632345]]\n",
      "Layer 2 = [[1.39860801]]\n",
      "Output = [[1]]\n",
      "==============================================\n",
      "Layer 0 = [[1 0]]\n",
      "Layer 1 = [[0.39844257 0.04717595 0.77687358 0.28017017]]\n",
      "Layer 2 = [[1.25208706]]\n",
      "Output = [[1]]\n",
      "==============================================\n",
      "Layer 0 = [[1 1]]\n",
      "Layer 1 = [[0.83859199 0.34204879 1.29040608 0.89611002]]\n",
      "Layer 2 = [[2.64840551]]\n",
      "Output = [[0]]\n",
      "==============================================\n",
      "Error:7.236487950581492\n",
      "[[0.         0.         0.         0.        ]\n",
      " [0.44064803 0.29531648 0.51416037 0.61632345]\n",
      " [0.39844257 0.04717595 0.77687358 0.28017017]\n",
      " [0.83859199 0.34204879 1.29040608 0.89611002]]\n",
      "********** Iteration: 5 *************\n",
      "Layer 0 = [[0 0]]\n",
      "Layer 1 = [[0. 0. 0. 0.]]\n",
      "Layer 2 = [[0.]]\n",
      "Output = [[0]]\n",
      "==============================================\n",
      "Layer 0 = [[0 1]]\n",
      "Layer 1 = [[0.43831373 0.29323924 0.51122103 0.61452772]]\n",
      "Layer 2 = [[1.38650458]]\n",
      "Output = [[1]]\n",
      "==============================================\n",
      "Layer 0 = [[1 0]]\n",
      "Layer 1 = [[0.39622059 0.04519864 0.77407569 0.2784609 ]]\n",
      "Layer 2 = [[1.24059974]]\n",
      "Output = [[1]]\n",
      "==============================================\n",
      "Layer 0 = [[1 1]]\n",
      "Layer 1 = [[0.83405536 0.33801096 1.284694   0.89262061]]\n",
      "Layer 2 = [[2.62491611]]\n",
      "Output = [[0]]\n",
      "==============================================\n",
      "Error:7.097458630278672\n",
      "[[0.         0.         0.         0.        ]\n",
      " [0.43831373 0.29323924 0.51122103 0.61452772]\n",
      " [0.39622059 0.04519864 0.77407569 0.2784609 ]\n",
      " [0.83405536 0.33801096 1.284694   0.89262061]]\n",
      "********** Iteration: 6 *************\n",
      "Layer 0 = [[0 0]]\n",
      "Layer 1 = [[0. 0. 0. 0.]]\n",
      "Layer 2 = [[0.]]\n",
      "Output = [[0]]\n",
      "==============================================\n",
      "Layer 0 = [[0 1]]\n",
      "Layer 1 = [[0.43601419 0.29118936 0.50832749 0.61276103]]\n",
      "Layer 2 = [[1.37463819]]\n",
      "Output = [[1]]\n",
      "==============================================\n",
      "Layer 0 = [[1 0]]\n",
      "Layer 1 = [[0.39403254 0.04324812 0.77132243 0.27677991]]\n",
      "Layer 2 = [[1.22933865]]\n",
      "Output = [[1]]\n",
      "==============================================\n",
      "Layer 0 = [[1 1]]\n",
      "Layer 1 = [[0.82958691 0.33402692 1.2790717  0.8891881 ]]\n",
      "Layer 2 = [[2.60188675]]\n",
      "Output = [[0]]\n",
      "==============================================\n",
      "Error:6.96276463843405\n",
      "[[0.         0.         0.         0.        ]\n",
      " [0.43601419 0.29118936 0.50832749 0.61276103]\n",
      " [0.39403254 0.04324812 0.77132243 0.27677991]\n",
      " [0.82958691 0.33402692 1.2790717  0.8891881 ]]\n",
      "********** Iteration: 7 *************\n",
      "Layer 0 = [[0 0]]\n",
      "Layer 1 = [[0. 0. 0. 0.]]\n",
      "Layer 2 = [[0.]]\n",
      "Output = [[0]]\n",
      "==============================================\n",
      "Layer 0 = [[0 1]]\n",
      "Layer 1 = [[0.43374858 0.28916623 0.50547861 0.61102267]]\n",
      "Layer 2 = [[1.36300195]]\n",
      "Output = [[1]]\n",
      "==============================================\n",
      "Layer 0 = [[1 0]]\n",
      "Layer 1 = [[0.39187759 0.0413238  0.76861272 0.2751265 ]]\n",
      "Layer 2 = [[1.21829719]]\n",
      "Output = [[1]]\n",
      "==============================================\n",
      "Layer 0 = [[1 1]]\n",
      "Layer 1 = [[0.82518501 0.33009546 1.27353696 0.88581109]]\n",
      "Layer 2 = [[2.57930401]]\n",
      "Output = [[0]]\n",
      "==============================================\n",
      "Error:6.8322332598279605\n",
      "[[0.         0.         0.         0.        ]\n",
      " [0.43374858 0.28916623 0.50547861 0.61102267]\n",
      " [0.39187759 0.0413238  0.76861272 0.2751265 ]\n",
      " [0.82518501 0.33009546 1.27353696 0.88581109]]\n",
      "********** Iteration: 8 *************\n",
      "Layer 0 = [[0 0]]\n",
      "Layer 1 = [[0. 0. 0. 0.]]\n",
      "Layer 2 = [[0.]]\n",
      "Output = [[0]]\n",
      "==============================================\n",
      "Layer 0 = [[0 1]]\n",
      "Layer 1 = [[0.43151608 0.28716926 0.50267332 0.60931194]]\n",
      "Layer 2 = [[1.35158918]]\n",
      "Output = [[1]]\n",
      "==============================================\n",
      "Layer 0 = [[1 0]]\n",
      "Layer 1 = [[0.38975495 0.03942507 0.76594548 0.27349998]]\n",
      "Layer 2 = [[1.207469]]\n",
      "Output = [[1]]\n",
      "==============================================\n",
      "Layer 0 = [[1 1]]\n",
      "Layer 1 = [[0.82084808 0.3262154  1.26808767 0.88248822]]\n",
      "Layer 2 = [[2.55715503]]\n",
      "Output = [[0]]\n",
      "==============================================\n",
      "Error:6.705700207148921\n",
      "[[0.         0.         0.         0.        ]\n",
      " [0.43151608 0.28716926 0.50267332 0.60931194]\n",
      " [0.38975495 0.03942507 0.76594548 0.27349998]\n",
      " [0.82084808 0.3262154  1.26808767 0.88248822]]\n",
      "********** Iteration: 9 *************\n",
      "Layer 0 = [[0 0]]\n",
      "Layer 1 = [[0. 0. 0. 0.]]\n",
      "Layer 2 = [[0.]]\n",
      "Output = [[0]]\n",
      "==============================================\n",
      "Layer 0 = [[0 1]]\n",
      "Layer 1 = [[0.42931592 0.28519786 0.49991057 0.60762817]]\n",
      "Layer 2 = [[1.34039351]]\n",
      "Output = [[1]]\n",
      "==============================================\n",
      "Layer 0 = [[1 0]]\n",
      "Layer 1 = [[0.38766386 0.03755139 0.76331969 0.27189971]]\n",
      "Layer 2 = [[1.19684798]]\n",
      "Output = [[1]]\n",
      "==============================================\n",
      "Layer 0 = [[1 1]]\n",
      "Layer 1 = [[0.81657458 0.32238561 1.26272178 0.87921816]]\n",
      "Layer 2 = [[2.53542743]]\n",
      "Output = [[0]]\n",
      "==============================================\n",
      "Error:6.5830091344092665\n",
      "[[0.         0.         0.         0.        ]\n",
      " [0.42931592 0.28519786 0.49991057 0.60762817]\n",
      " [0.38766386 0.03755139 0.76331969 0.27189971]\n",
      " [0.81657458 0.32238561 1.26272178 0.87921816]]\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(10):\n",
    "    layer_2_error = 0\n",
    "\n",
    "    array = np.empty((4,hidden_size))\n",
    "\n",
    "    print(f\"********** Iteration: {iteration} *************\")\n",
    "    for i in range(len(streetlights)):\n",
    "        # forward pass\n",
    "        layer_0 = streetlights[i:i+1]\n",
    "        print(f'Layer 0 = {layer_0}')\n",
    "        layer_1 = relu(np.dot(layer_0,weights_0_1))\n",
    "        print(f'Layer 1 = {layer_1}')\n",
    "        layer_2 = np.dot(layer_1,weights_1_2)\n",
    "        print(f'Layer 2 = {layer_2}')\n",
    "\n",
    "        array[i] = layer_1\n",
    "        # backward pass\n",
    "        layer_2_error += np.sum((layer_2 - walk_vs_stop[i:i+1]) ** 2)\n",
    "        \n",
    "        layer_2_delta = (layer_2 - walk_vs_stop[i:i+1])\n",
    "        layer_1_delta = layer_2_delta.dot(weights_1_2.T) * relu2deriv(layer_1)\n",
    "\n",
    "        # layer_1_delta = layer_1 - layer_2\n",
    "        # weight updating\n",
    "        weights_1_2 -= alpha * layer_1.T.dot(layer_2_delta)\n",
    "        weights_0_1 -= alpha * layer_0.T.dot(layer_1_delta)\n",
    "        print(f'Output = {walk_vs_stop[i:i+1]}')\n",
    "        print(\"==============================================\")\n",
    "            \n",
    "    print(\"Error:\" + str(layer_2_error))\n",
    "    print(f'{array}')\n",
    "    \n",
    "    data_fig.data[0].x = array[:,0]\n",
    "    data_fig.data[0].y = array[:,1]\n",
    "\n",
    "    import time\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.2913239088494768\n",
      "Epoch 1000, Loss: 0.25013205911182146\n",
      "Epoch 2000, Loss: 0.2500839755180796\n",
      "Epoch 3000, Loss: 0.2500575150938403\n",
      "Epoch 4000, Loss: 0.2500415143068478\n",
      "Epoch 5000, Loss: 0.25003101962364\n",
      "Epoch 6000, Loss: 0.2500236895266624\n",
      "Epoch 7000, Loss: 0.25001833734402235\n",
      "Epoch 8000, Loss: 0.25001431284494097\n",
      "Epoch 9000, Loss: 0.2500112294597659\n",
      "Predictions:\n",
      "[[0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Helper functions\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_derivative(x):\n",
    "    return np.where(x > 0, 1, 0)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "def mse_loss(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "# XOR input and output\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "# Initialize parameters\n",
    "# np.random.seed(42)\n",
    "\n",
    "# Number of neurons in each layer\n",
    "input_neurons = 2\n",
    "hidden_neurons = 2\n",
    "output_neurons = 1\n",
    "\n",
    "# Weights and biases initialization\n",
    "weights_input_hidden = np.random.rand(input_neurons, hidden_neurons)\n",
    "weights_hidden_output = np.random.rand(hidden_neurons, output_neurons)\n",
    "bias_hidden = np.random.rand(1, hidden_neurons)\n",
    "bias_output = np.random.rand(1, output_neurons)\n",
    "\n",
    "# Training parameters\n",
    "learning_rate = 0.01\n",
    "epochs = 10000\n",
    "\n",
    "# Training the model\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass\n",
    "    hidden_layer_input = np.dot(X, weights_input_hidden) + bias_hidden\n",
    "    hidden_layer_output = relu(hidden_layer_input)\n",
    "    \n",
    "    output_layer_input = np.dot(hidden_layer_output, weights_hidden_output) + bias_output\n",
    "    output_layer_output = sigmoid(output_layer_input)\n",
    "    \n",
    "    # Compute the loss\n",
    "    loss = mse_loss(y, output_layer_output)\n",
    "    \n",
    "    # Backpropagation\n",
    "    error_output_layer = y - output_layer_output\n",
    "    d_output = error_output_layer * sigmoid_derivative(output_layer_output)\n",
    "    \n",
    "    error_hidden_layer = d_output.dot(weights_hidden_output.T)\n",
    "    d_hidden = error_hidden_layer * relu_derivative(hidden_layer_output)\n",
    "    \n",
    "    # Update weights and biases\n",
    "    weights_hidden_output += hidden_layer_output.T.dot(d_output) * learning_rate\n",
    "    bias_output += np.sum(d_output, axis=0, keepdims=True) * learning_rate\n",
    "    \n",
    "    weights_input_hidden += X.T.dot(d_hidden) * learning_rate\n",
    "    bias_hidden += np.sum(d_hidden, axis=0, keepdims=True) * learning_rate\n",
    "\n",
    "    # Optionally print the loss at certain intervals\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss}')\n",
    "\n",
    "# Making predictions\n",
    "hidden_layer_input = np.dot(X, weights_input_hidden) + bias_hidden\n",
    "hidden_layer_output = relu(hidden_layer_input)\n",
    "\n",
    "output_layer_input = np.dot(hidden_layer_output, weights_hidden_output) + bias_output\n",
    "output_layer_output = sigmoid(output_layer_input)\n",
    "\n",
    "print('Predictions:')\n",
    "print(np.round(output_layer_output))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
